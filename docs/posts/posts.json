[
  {
    "path": "posts/2023-03-21-modeling-competition/",
    "title": "Getting 3rd in Modeling Competition",
    "description": "Somehow I got on the podium for a model-building competition in my data science class",
    "author": [
      {
        "name": "Grant Li",
        "url": {}
      }
    ],
    "date": "2023-03-21",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nOn the wrong track\r\nOn the right track\r\nWhat more could I have done?\r\n\r\nIn the data science class I’m taking, they hosted a model-building competition across all three sections of the class, meaning there were at least 100 students participating, maybe 200. We had to build a model to predict the amount of money a bank would make back on a loan. The goal was to build a linear regression model that would produce the lowest RMSE.\r\n\r\nRoot Mean Squared Error, basically you can think of it as a statistical measure to see how accurate your model is. In general you want it smaller.\r\n\r\nOn the wrong track\r\nAt the start, I did VIF testing on all the continuous variables. The VIF testing showed that none of them were egregiously multicollinear, only 2 or 3 of them were in the 5-10 range, which our professors had said was not good, but can be accepted nevertheless.\r\n\r\nVIF stands for Variable Inflation Factor, which basically just measures how much multicollinearity there is between your variables. Multicollinearity is where two variables are highly correlated, when really the variables in the model should be independent.\r\n\r\nBecause our variable subsetting algorithms didn’t allow for categorical variables, I simply tried making models by running forward stepwise variable subsetting and then K-folds cross validation on the continuous variables and then adding categorical variables into the model after. I tried this for a day or two and it was clear that my RMSE wasn’t going to get under the 650 threshold that we had to get under for full credit on this assignment. It was stuck at 800 for a while.\r\nOn the right track\r\nI decided that instead, I would try turn all the categorical variables into dummies, and do it all over again.\r\n\r\nA dummy variable is essentially turning, for example, a variable that has yes or no responses into two separate columns of yes and no, with 1s and 0s as the response. This way, the data becomes numerical and can be put into functions that otherwise only took continuous/numerical variables. Additionally, it allows the model to choose only the dummy variables that matter, like perhaps only the yes column with 1s and 0s is statistically significant, and the no column with 1s and 0s is not.\r\n\r\n\r\n\r\n\r\nI technically should have done exploratory data analysis (EDA) and picked a few variables that would have worked best. But since my computer could handle it, I turned every single categorical variable into dummy variables, except emp_title and earliest_cr_line, since those had just way too many categories that it honestly wasn’t worth it. Even then, the forward stepwise variable subsetting took 20 minutes each time. While I ended up pursuing the brute-force method, I did end up doing EDA at the end which basically corroborated everything that was produced below.\r\nSince our k-folds cross validation function only takes 4 variables, I used the model with the 4 best predictors to find what I should put into the k-folds cross validation function. The best 4 variables were out_prncp_inv, loan_amnt, int_rate, and term_36_months, which is a dummy variable created from the term variable\r\n\r\n\r\n\r\nThen I put this through k-folds cross-validation, which added selected interactions. The k-folds cross validation was pretty impressive, because after working on this for days, it kind of stunned me to just watch the RMSE keep going down like that all the way to the 400s.\r\n\r\n\r\n\r\nThese were the interactions that the k-folds cross validation found.\r\n\r\n\r\n\r\nI then used the BIC curve to find the optimal number of predictors from the most recent forward stepwise variable subsetting.\r\n\r\nBIC stands for Bayesian information criterion. The BIC curve in this case stands for a curve that after variable subsetting, shows you what it believes to be the most ideal number of predictors is.\r\n\r\n\r\n\r\n\r\nThe curve says 33, but I found the 32 best predictors, not that the difference really matters that much. Here are some of them, since I literally can’t fit them in my screenshot.\r\n\r\n\r\n\r\nI tested each one of them by adding them into the model formula that we got from the k-folds cross validation, and saw if it decreased RMSE. After doing so, the ones that decreased the RMSE by any appreciable amount were grade_a and total_rec_late_fee. The final model formula looked like this, including the selected interactions earlier:\r\n\r\n# K-folds model with new predictors after testing predictors that appear in the \r\n# 32 predictor model\r\n\r\nmodel = sm.ols('money_made_inv ~ \r\n               out_prncp_inv + \r\n               loan_amnt + \r\n               int_rate + \r\n               term_36_months + \r\n               grade_a + \r\n               total_rec_late_fee' + \r\n                 selected_interactions, data = trainCopy).fit()\r\n\r\nAfter submitting this, it turns out that I was in the top 3 student submissions!\r\n\r\n\r\n\r\nNumber 1 is a professor, Arvind Krishna, so he doesn’t count. This was the public submission leaderboard, which only calculated the RMSE on 30% of the test data. I had no clue until the competition ended that there was also a private submission leaderboard that calculated the RMSE on 70% of the test data. That was the actual “final” ranking, where I was 9th, which still really good.\r\n\r\n\r\n\r\nNevertheless, I kind of like my 3rd place finish on the public leaderboard more, not because I was 3rd as opposed to 9th, but because there were things like outlier removal, which did not lower the RMSE on the public submission board so I didn’t include it in my final submission, but could have on the private one if I could only have just seen the RMSE.\r\nWhat more could I have done?\r\nI could have also done some regularization with lasso or ridge.\r\n\r\nLasso and ridge help balance out the coefficients, and prevent the model from overfitting.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-03-21-modeling-competition/selected.png",
    "last_modified": "2023-03-21T21:24:51-05:00",
    "input_file": "modeling-competition.knit.md",
    "preview_width": 1249,
    "preview_height": 178
  },
  {
    "path": "posts/2023-03-18-foia-data-portal/",
    "title": "FOIA Data Dashboard",
    "description": "A dashboard I built for FOIA data",
    "author": [
      {
        "name": "Grant Li",
        "url": {}
      }
    ],
    "date": "2023-03-18",
    "categories": [],
    "contents": "\r\nFor our final project in my data science class, we had the option to either make static data visualizations, or a shiny application. I decided to make a shiny application with a data dashboard on Freedom of Information Act (FOIA) data. You can find this dashboard at https://grantli.shinyapps.io/foiaapp/.\r\nMy research at the Deportation Research Clinic involves a lot of FOIA requests, particularly with the Executive Office of Immigration Review (EOIR). The government often takes far longer to respond than what the law allows for. To force the government to follow the law and respond to our FOIA requests, we file complaints in court. One of the arguments that we have wanted to make with regards to this is that our the government under-funds EOIR’s FOIA response capabilities. To help prove this and help others have access to similar information, I built this portal using Department of Justice (DOJ) FOIA data.\r\nEssentially, government departments or agencies must put out a FOIA report every year with statistics on how they responded to FOIA requests that year. Unfortunately, up until now, much of this data was quite inaccessible. They are usually in XML files or PDF tables, and not aggregated well across agencies. There have been no data visualizations of this type of data. Luckily, there is a data portal where you can download CSV’s (comma-separated values, just think Excel spreadsheet) of department level data at: https://www.foia.gov/reports.html. Unfortunately the data portal sort of broke down (for me, at least) every time too many statistical measures were selected, so I downloaded them separately and manually collated them together.\r\nI hope that providing this dashboard will help make this data more accessible and understandable. Already, the data corroborates the argument that the EOIR’s FOIA respose capabilities are seriously underfunded. In the future, I intend on expanding it if I can to provide data for not just the DOJ.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-03-18T12:41:12-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-01-31-chinese-demographics-in-litchfield-county/",
    "title": "Chinese Demographics in Litchfield County",
    "description": "Using census data to investigate Chinese demographics in Litchfield County, CT",
    "author": [
      {
        "name": "Grant Li",
        "url": {}
      }
    ],
    "date": "2023-01-31",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nChinese demographics in Litchfield County, CT\r\n\r\nI recently learned how to do maps in an R data visualization class at school. I found it pretty interesting. For example, here is a map I made for Rochester, New York that shows major roads and elevation. We were told we could make this as simple or as cool as we wanted, so I actually tried to do something unique and cool. I’ve always loved topographical maps because I love war history, and topography is key to understanding much of war strategy.\r\n\r\n\r\n\r\nHollister (2022); Pebesma (2022); Walker and Herman (2023); Garnier (2021); Pebesma (2018); Wickham et al. (2019);1\r\nChinese demographics in Litchfield County, CT\r\nLater, there was a bonus (worth 0 points?!) to make an interactive map on your own. They did not actually teach us how to do the interactive part, so it was entirely up to us whether we wanted to teach ourselves or not. After doing a lot of digging and research, I figured out how to make an interactive map for the Chinese population in Litchfield County, Connecticut. I was specifically interested in this particular county because I am Chinese and grew up in New Milford, a town in Litchfield County.\r\n\r\n\r\n\r\nCheng, Karambelkar, and Xie (2022)\r\nWhat can we learn from this map? There appears to be 4 main concentrations of Chinese people around Litchfield County: New Milford (yellow), Kent on the middle-left (green), Salisbury on the top-left (blue), and some patches of turquoise near Waterbury on the bottom-right.\r\nNow if you are from the area, you will know that Waterbury is quite big of a city, so it’s entirely unsurprising that there are more Chinese people living in their suburbs. Additionally, New Milford is the last sizeable population aside from Torrington before going any further north, and also acts somewhat like a suburb of Danbury. It makes sense that there are some Chinese residents here. However, Kent and Salisbury are a little more puzzling; both have about two streets in their town. Even New Milford having 103 people in that one yellow census tract is extremely surprising: having lived there, I basically knew almost every Chinese family in town and could basically count them on my fingers. Where were they all?\r\nWell it turns out, what New Milford, Kent, and Salisbury all have in common are private schools. The rich, old money, elite kind. In New Milford, we have the Canterbury School, Kent has the Kent School, and Salisbury has perhaps the most notorious of the three: the Hotchkiss School. Rich Chinese families are sending their kids to these private schools. There are probably a bunch of Chinese students within Canterbury’s campus that I have simply never seen before (I attended the town’s public school, New Milford High School).\r\nI hope you found this interesting!\r\n\r\n\r\n\r\nCheng, Joe, Bhaskar Karambelkar, and Yihui Xie. 2022. Leaflet: Create Interactive Web Maps with the JavaScript Leaflet Library. https://rstudio.github.io/leaflet/.\r\n\r\n\r\nGarnier, Simon. 2021. Viridis: Colorblind-Friendly Color Maps for r. https://CRAN.R-project.org/package=viridis.\r\n\r\n\r\nHollister, Jeffrey. 2022. Elevatr: Access Elevation Data from Various APIs. https://github.com/jhollist/elevatr/.\r\n\r\n\r\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\r\n\r\n\r\n———. 2022. Sf: Simple Features for r.\r\n\r\n\r\nWalker, Kyle, and Matt Herman. 2023. Tidycensus: Load US Census Boundary and Attribute Data as Tidyverse and Sf-Ready Data Frames. https://walker-data.com/tidycensus/.\r\n\r\n\r\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\r\n\r\n\r\nRochester municipal boundaries shape file was obtained here: https://data.cityofrochester.gov/datasets/8d69bba78ba94305a467e9e8bf497570_0/explore?location=43.185221%2C-77.619085%2C5.64↩︎\r\n",
    "preview": "posts/2023-01-31-chinese-demographics-in-litchfield-county/distill-preview.png",
    "last_modified": "2023-03-18T10:46:36-07:00",
    "input_file": {},
    "preview_width": 787,
    "preview_height": 486
  }
]
